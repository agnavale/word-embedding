First I used Dense layer with linear activation and second dense layer with softmax activation. Let v: vocablury_size and n: no_units_in_first_dense_layer. So the weights for first layer be W matrix: V x n is the center_word matrix. and the weights for output layer be W' matrix: n x V is the context_word matrix. Output equation is Y = softmax(W' W X ). This is actually the probability of context_word given center_word. and n is the size of word_embeddings. I have used n = 64. To plot the 2-D graph we have reduce diamentions of word_embeddings to 2.
